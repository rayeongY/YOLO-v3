{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "\r\n",
    "from data.yolo_dataset import YoloDataset, collate_fn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch import nn\r\n",
    "\r\n",
    "\r\n",
    "class YOLOv3Loss(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.mse = nn.MSELoss()\r\n",
    "        self.bce = nn.BCEWithLogitsLoss()                       ## Do I have to set reduction? \r\n",
    "        self.multiMargin = nn.MultiLabelSoftMarginLoss()        ## Do I have to set reduction? (2)\r\n",
    "                                                                ## https://cvml.tistory.com/26\r\n",
    "\r\n",
    "        \r\n",
    "    def forward(self, pred, target, scale, anchors):\r\n",
    "\r\n",
    "        ## no_obj_loss(No Object Loss):     Loss for objectness score      of non-object-assigned BBOXes\r\n",
    "        ## is_obj_loss(Object Loss):        Loss for objectness score      of     object-assigned BBOXes\r\n",
    "        ## coord_loss(Coordinates Loss):    Loss for predicted coordinates of     object-assigned BBOXes\r\n",
    "        ## class_loss(Classification Loss): Loss for predicted class-ids   of     object-assigned BBOXes \r\n",
    "\r\n",
    "        is_assigned = pred[..., 4] == 1     ## tensor([(element == 1) for element in 4th column of pred])   ## e.g. tensor([True, False, False, ...])\r\n",
    "        no_assigned = pred[..., 4] == 0     ## If use these boolean-list tensor as a indices,\r\n",
    "                                            ##    we can extract the only rows from target(label) tensor -- whose 4th column element(objectness score) is 1-or-0\r\n",
    "\r\n",
    "        scale = torch.tensor(scale).reshape(-1, 1).repeat(1, 2).reshape(1, 1, 1, 1, 2)      ## 13 -> [[[[[13, 13]]]]]\r\n",
    "        cell_offset = (pred[..., :2].floor_divide(scale)) * scale                           ## ??????????????????\r\n",
    "        pred[..., :2] = pred[..., :2] - cell_offset\r\n",
    "\r\n",
    "        no_obj_loss = self.get_loss(pred[...,  4][no_assigned], target[...,  4][no_assigned], anchors, opt=\"NO_OBJ\")\r\n",
    "        is_obj_loss = self.get_loss(pred[...,  4][is_assigned], target[...,  4][is_assigned], anchors, opt=\"IS_OBJ\")\r\n",
    "        coord_loss =  self.get_loss(pred[..., :4][is_assigned], target[..., :4][is_assigned], anchors, opt=\"COORD\")\r\n",
    "        class_loss =  self.get_loss(pred[..., 5:][is_assigned], target[..., 5:][is_assigned], anchors, opt=\"CLASS\")\r\n",
    "        \r\n",
    "        loss = no_obj_loss + is_obj_loss + coord_loss + class_loss\r\n",
    "        return loss\r\n",
    "\r\n",
    "\r\n",
    "    def get_loss(self, pred, target, anchors, opt):\r\n",
    "        \r\n",
    "        if opt == \"NO_OBJ\":\r\n",
    "            loss = self.bce(pred, target)\r\n",
    "            return loss\r\n",
    "\r\n",
    "        elif opt == \"IS_OBJ\":\r\n",
    "            loss = self.bce(torch.sigmoid(pred), target)            ## If use [wh_IOU * target] instead of [target], MSE loss is better . . . maybe.\r\n",
    "            return loss                                             ##    cause [target] and [wh_IOU * target] values differ in \"Discrete\"/\"Continuous\"\r\n",
    "\r\n",
    "        elif opt == \"COORD\":\r\n",
    "            pred_bboxes =   torch.cat([torch.sigmoid(pred[..., 0:2]), torch.exp(pred[..., 2:4])          ], dim=1)\r\n",
    "            target_bboxes = torch.cat([              pred[..., 0:2] ,          (pred[..., 2:4] / anchors)], dim=1)\r\n",
    "            loss = self.mse(pred_bboxes, target_bboxes)\r\n",
    "            return loss\r\n",
    "\r\n",
    "        elif opt == \"CLASS\":\r\n",
    "            loss = self.multiMargin(pred, target)\r\n",
    "            return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def train(\r\n",
    "        model,\r\n",
    "        train_loader,\r\n",
    "        loss_func,\r\n",
    "        dataset_option,\r\n",
    "        model_option,\r\n",
    "        epoch,\r\n",
    "        # anchors,\r\n",
    "        ):\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device='cpu')       ## [13, 26, 52]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device='cpu')\r\n",
    "\r\n",
    "    for i, batch_img, batch_label, batch_img_path in enumerate(train_loader, 0):\r\n",
    "        batch_size = batch_img.size(0)\r\n",
    "        \r\n",
    "        #################\r\n",
    "        ##  FORWARDING ##\r\n",
    "        #################\r\n",
    "        pred = model(batch_img)                                                      ### batch_img: tensor(   N, 3, 416, 416) . . . . . . . . . . . N = batch_size\r\n",
    "        loss = ( loss_func(pred[0], batch_label[0], scales[0], anchor=anchors[0])    ######## pred: tensor(3, N, 3, S, S, 1 + 4 + class_offset) . . S = scale_size\r\n",
    "               + loss_func(pred[1], batch_label[1], scales[1], anchor=anchors[1])    # batch_label: tensor(3, N, 3, S, S, 1 + 4 + class_offset)\r\n",
    "               + loss_func(pred[2], batch_label[2], scales[2], anchor=anchors[2]) )  ##### anchors: tensor(3,    3,       2) . . . is list of pairs(anch_w, anch_h)\r\n",
    "\r\n",
    "        #################\r\n",
    "        ## BACKWARDING ##\r\n",
    "        #################\r\n",
    "        loss.backward()\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def valid(\r\n",
    "    model,\r\n",
    "    valid_loader,\r\n",
    "    model_option,\r\n",
    "    epoch,\r\n",
    "    # anchors,\r\n",
    "    ):\r\n",
    "    model.eval()\r\n",
    "    true_pred_num = 0\r\n",
    "    gt_num = 0\r\n",
    "\r\n",
    "    for i, batch_img, batch_label, batch_img_path in enumerate(valid_loader, 0):\r\n",
    "\r\n",
    "        pred = model(batch_img)\r\n",
    "\r\n",
    "        ## Post-Processing?\r\n",
    "\r\n",
    "        ## Get the number of both true predictions and ground truth\r\n",
    "\r\n",
    "\r\n",
    "    ## Examine Accuracy\r\n",
    "    acc = (true_pred_num / gt_num + 1e-16) * 100\r\n",
    "    \r\n",
    "    return acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "dataset_option = {  \"DATASET\": {\r\n",
    "                        \"NAME\": \"ship\",\r\n",
    "                        \"ROOT\": \"../datasets/ship\",\r\n",
    "                        \"CLASSES\": {\r\n",
    "                            #    \"선박\": 0, \"부표\": 1, \"어망부표\": 2,\r\n",
    "                            #    \"해상풍력\": 3, \"등대\": 4, \"기타부유물\" : 5\r\n",
    "                               \"선박\": 0, \"부표\": 1, \"어망부표\": 1,\r\n",
    "                               \"해상풍력\": 1, \"등대\": 1, \"기타부유물\" : 1\r\n",
    "                        },\r\n",
    "                        \"NUM_CLASSES\": 2\r\n",
    "                     }\r\n",
    "                 }\r\n",
    "\r\n",
    "model_option = {\"YOLOv3\": {\r\n",
    "                     \"SCALES\": [13, 26, 52],\r\n",
    "                     \"NUM_ANCHORS\": 9,\r\n",
    "                     \"ANCHORS\": [[( 10, 13), ( 16,  30), ( 33,  23)],\r\n",
    "                                 [( 30, 61), ( 62,  45), ( 59, 119)],\r\n",
    "                                 [(116, 90), (156, 198), (373, 326)]]\r\n",
    "                    }\r\n",
    "               }\r\n",
    "\r\n",
    "optim_option = {\"OPTIMIZER\": {\r\n",
    "                     \"METHOD\": \"adam\",\r\n",
    "                     \"BATCH_SIZE\": 32,\r\n",
    "                     \"EPOCHS\": 10,\r\n",
    "                     \"LR\": 1e-4,\r\n",
    "                    }\r\n",
    "               }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "epochs = optim_option[\"OPTIMIZER\"][\"EPOCHS\"]\r\n",
    "batch_size = optim_option[\"OPTIMIZER\"][\"BATCH_SIZE\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = Net()\r\n",
    "loss_function = YOLOv3Loss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##############\r\n",
    "## DATALOAD ##\r\n",
    "##############\r\n",
    "train_dataset = YoloDataset(dataset_option, model_option, split=\"train\")\r\n",
    "train_loader = DataLoader(train_dataset, batch_size, collate_fn=collate_fn)\r\n",
    "valid_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "valid_loader = DataLoader(valid_dataset, batch_size, collate_fn=collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(epochs):\r\n",
    "    ###########\r\n",
    "    ## TRAIN ##\r\n",
    "    ###########\r\n",
    "    train(  \r\n",
    "            model,\r\n",
    "            train_loader,\r\n",
    "            loss_function,\r\n",
    "            dataset_option,\r\n",
    "            model_option,\r\n",
    "            epoch,\r\n",
    "            # anchors,\r\n",
    "          )\r\n",
    "        \r\n",
    "    #######################\r\n",
    "    ## VALID (INFERENCE) ##\r\n",
    "    #######################\r\n",
    "    acc = valid(\r\n",
    "                 model,\r\n",
    "                 valid_loader,\r\n",
    "                 model_option,\r\n",
    "                 epoch,\r\n",
    "                 # anchors,\r\n",
    "               )\r\n",
    "\r\n",
    "    print(f\"Epoch: ({epoch + 1}/{epochs}) . . . [acc: {acc:.2f}]\")\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "3cbf2cfe2af17255c7550a0a36495165331228ad52d7cf7dc2787e8b35bbde01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}