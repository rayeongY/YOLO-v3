{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "import argparse\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"sample_train.ipynb\"))))\r\n",
    "from common.parser import yaml_parser\r\n",
    "from common.recoder import save_checkpoint\r\n",
    "from common.cocoeval4yolo import CocoEval\r\n",
    "from data.yolo_dataset import *\r\n",
    "# from model.loss import YOLOv3Loss\r\n",
    "from model.model import Darknet4YOLOv3\r\n",
    "from model.darknet2pytorch import DarknetParser, yolo_forward_dynamic\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import easydict\r\n",
    "\r\n",
    "args = easydict.EasyDict({\r\n",
    "    \"config\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolov3.cfg\",\r\n",
    "    # \"config\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.cfg\",\r\n",
    "    \"weight\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov3-608.weights\",\r\n",
    "    \"dataset\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/dataset/yolo_dataset.yml\",\r\n",
    "    \"model\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolo_model.yml\",\r\n",
    "    \"optimizer\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/optimizer/optimizer.yml\",\r\n",
    "    \"weight_save_dir\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/weights\"\r\n",
    "})\r\n",
    "\r\n",
    "\r\n",
    "dataset_option = yaml_parser(args.dataset)\r\n",
    "model_option = yaml_parser(args.model)\r\n",
    "optimizer_option = yaml_parser(args.optimizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "######################\r\n",
    "## BUILD DATALOADER ##\r\n",
    "######################\r\n",
    "# train_set_num, train_loader, _ = build_DataLoader(dataset_option, model_option, optimizer_option)\r\n",
    "\r\n",
    "train_dataset = YoloDataset(dataset_option, model_option, split=\"train\")\r\n",
    "valid_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "train_loader = DataLoader(train_dataset,\r\n",
    "                          batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"],\r\n",
    "                          shuffle=True,\r\n",
    "                          collate_fn=collate_fn,\r\n",
    "                          drop_last=True)\r\n",
    "valid_loader = DataLoader(valid_dataset,\r\n",
    "                          batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"],\r\n",
    "                          shuffle=True,\r\n",
    "                          collate_fn=collate_fn,\r\n",
    "                          drop_last=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# device = torch.device('cpu')\r\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "###########################\r\n",
    "## BUILD MODEL & LOSS_fn ##\r\n",
    "###########################\r\n",
    "# model = DarknetParser(args.config, args.weight).to(device)\r\n",
    "model = Darknet4YOLOv3(args.config, args.weight).to(device)\r\n",
    "model = torch.nn.DataParallel(model)\r\n",
    "# loss_function = yolo_forward_dynamic\r\n",
    "# loss_function = YOLOv3Loss()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "load weights from : 'C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov3-608.weights'\n",
      "Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0 convolutional load weights : [0.004]/[236.518] mb\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "1 convolutional load weights : [0.075]/[236.518] mb\n",
      "Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2 convolutional load weights : [0.083]/[236.518] mb\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "3 convolutional load weights : [0.155]/[236.518] mb\n",
      "4 shortcut     load weights : [0.155]/[236.518] mb\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "5 convolutional load weights : [0.438]/[236.518] mb\n",
      "Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "6 convolutional load weights : [0.470]/[236.518] mb\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "7 convolutional load weights : [0.753]/[236.518] mb\n",
      "8 shortcut     load weights : [0.753]/[236.518] mb\n",
      "Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "9 convolutional load weights : [0.786]/[236.518] mb\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "10 convolutional load weights : [1.069]/[236.518] mb\n",
      "11 shortcut     load weights : [1.069]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "12 convolutional load weights : [2.198]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "13 convolutional load weights : [2.325]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "14 convolutional load weights : [3.453]/[236.518] mb\n",
      "15 shortcut     load weights : [3.453]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "16 convolutional load weights : [3.580]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "17 convolutional load weights : [4.709]/[236.518] mb\n",
      "18 shortcut     load weights : [4.709]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "19 convolutional load weights : [4.836]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "20 convolutional load weights : [5.965]/[236.518] mb\n",
      "21 shortcut     load weights : [5.965]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "22 convolutional load weights : [6.092]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "23 convolutional load weights : [7.221]/[236.518] mb\n",
      "24 shortcut     load weights : [7.221]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "25 convolutional load weights : [7.348]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "26 convolutional load weights : [8.477]/[236.518] mb\n",
      "27 shortcut     load weights : [8.477]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "28 convolutional load weights : [8.604]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "29 convolutional load weights : [9.733]/[236.518] mb\n",
      "30 shortcut     load weights : [9.733]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "31 convolutional load weights : [9.860]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "32 convolutional load weights : [10.989]/[236.518] mb\n",
      "33 shortcut     load weights : [10.989]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "34 convolutional load weights : [11.116]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "35 convolutional load weights : [12.245]/[236.518] mb\n",
      "36 shortcut     load weights : [12.245]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "37 convolutional load weights : [16.752]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "38 convolutional load weights : [17.256]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "39 convolutional load weights : [21.764]/[236.518] mb\n",
      "40 shortcut     load weights : [21.764]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "41 convolutional load weights : [22.268]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "42 convolutional load weights : [26.776]/[236.518] mb\n",
      "43 shortcut     load weights : [26.776]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "44 convolutional load weights : [27.280]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "45 convolutional load weights : [31.787]/[236.518] mb\n",
      "46 shortcut     load weights : [31.787]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "47 convolutional load weights : [32.291]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "48 convolutional load weights : [36.799]/[236.518] mb\n",
      "49 shortcut     load weights : [36.799]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "50 convolutional load weights : [37.303]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "51 convolutional load weights : [41.811]/[236.518] mb\n",
      "52 shortcut     load weights : [41.811]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "53 convolutional load weights : [42.315]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "54 convolutional load weights : [46.823]/[236.518] mb\n",
      "55 shortcut     load weights : [46.823]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "56 convolutional load weights : [47.327]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "57 convolutional load weights : [51.834]/[236.518] mb\n",
      "58 shortcut     load weights : [51.834]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "59 convolutional load weights : [52.338]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "60 convolutional load weights : [56.846]/[236.518] mb\n",
      "61 shortcut     load weights : [56.846]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "62 convolutional load weights : [74.862]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "63 convolutional load weights : [76.870]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "64 convolutional load weights : [94.885]/[236.518] mb\n",
      "65 shortcut     load weights : [94.885]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "66 convolutional load weights : [96.893]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "67 convolutional load weights : [114.909]/[236.518] mb\n",
      "68 shortcut     load weights : [114.909]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "69 convolutional load weights : [116.916]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "70 convolutional load weights : [134.932]/[236.518] mb\n",
      "71 shortcut     load weights : [134.932]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "72 convolutional load weights : [136.940]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "73 convolutional load weights : [154.955]/[236.518] mb\n",
      "74 shortcut     load weights : [154.955]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "75 convolutional load weights : [156.963]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "76 convolutional load weights : [174.979]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "77 convolutional load weights : [176.987]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "78 convolutional load weights : [195.002]/[236.518] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "79 convolutional load weights : [197.010]/[236.518] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "80 convolutional load weights : [215.026]/[236.518] mb\n",
      "Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "81 convolutional load weights : [216.023]/[236.518] mb\n",
      "82 yolo         load weights : [216.023]/[236.518] mb\n",
      "83 route        load weights : [216.023]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "84 convolutional load weights : [216.527]/[236.518] mb\n",
      "85 upsample     load weights : [216.527]/[236.518] mb\n",
      "86 route        load weights : [216.527]/[236.518] mb\n",
      "Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "87 convolutional load weights : [217.281]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "88 convolutional load weights : [221.788]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "89 convolutional load weights : [222.292]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "90 convolutional load weights : [226.800]/[236.518] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "91 convolutional load weights : [227.304]/[236.518] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "92 convolutional load weights : [231.812]/[236.518] mb\n",
      "Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "93 convolutional load weights : [232.311]/[236.518] mb\n",
      "94 yolo         load weights : [232.311]/[236.518] mb\n",
      "95 route        load weights : [232.311]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "96 convolutional load weights : [232.438]/[236.518] mb\n",
      "97 upsample     load weights : [232.438]/[236.518] mb\n",
      "98 route        load weights : [232.438]/[236.518] mb\n",
      "Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "99 convolutional load weights : [232.627]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "100 convolutional load weights : [233.756]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "101 convolutional load weights : [233.883]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "102 convolutional load weights : [235.012]/[236.518] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "103 convolutional load weights : [235.139]/[236.518] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "104 convolutional load weights : [236.268]/[236.518] mb\n",
      "Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "105 convolutional load weights : [236.518]/[236.518] mb\n",
      "106 yolo         load weights : [236.518]/[236.518] mb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model.eval()\r\n",
    "\r\n",
    "coco_evaluator = CocoEval()\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    for i, batch_input in enumerate(tqdm(valid_loader, desc=\"valid\")):\r\n",
    "        batch_img = batch_input[\"img\"].to(device)\r\n",
    "\r\n",
    "        preds = model(batch_img)                             ## preds = [(boxes, confs), (boxes, confs), (boxes, confs)]\r\n",
    "        \r\n",
    "        \r\n",
    "        coco_evaluator.update(batch_input, preds)\r\n",
    "    \r\n",
    "mAP = coco_evaluator.eval()\r\n",
    "print(f\"mAP: {mAP}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "valid: 100%|██████████| 250/250 [02:57<00:00,  1.41it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.55s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.07s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.566\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.109\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.198\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.243\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.252\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "3cbf2cfe2af17255c7550a0a36495165331228ad52d7cf7dc2787e8b35bbde01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}