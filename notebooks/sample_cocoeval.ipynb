{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "import argparse\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"sample_train.ipynb\"))))\r\n",
    "from common.parser import yaml_parser\r\n",
    "from common.recoder import save_checkpoint\r\n",
    "from common.cocoeval4yolo import CocoEval\r\n",
    "from common.utils import compress_label_map\r\n",
    "from data.yolo_dataset import *\r\n",
    "from model.loss import YOLOv3Loss\r\n",
    "from model.model import Darknet4YOLOv3\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def train(\r\n",
    "        model,\r\n",
    "        train_loader,\r\n",
    "        loss_func,\r\n",
    "        optimizer,\r\n",
    "        optim_option,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device)       ## [13, 26, 52]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device)\r\n",
    "\r\n",
    "    for i, batch_input in enumerate(tqdm(train_loader, desc=\"train\")):\r\n",
    "        n_iteration = (optim_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] * epoch) + i\r\n",
    "\r\n",
    "        batch_img = batch_input[\"img\"].to(device)\r\n",
    "        batch_label = [label.to(device) for label in batch_input[\"label_map\"]]\r\n",
    "        \r\n",
    "        #################\r\n",
    "        ##  FORWARDING ##\r\n",
    "        #################\r\n",
    "        pred = model(batch_img)                                                       ### batch_img: tensor(   N, 3, 608, 608) . . . . . . . . . . . N = batch_size\r\n",
    "        loss = ( loss_func(pred[0], batch_label[0], scales[0], anchors=anchors[0])    ######## pred: tensor(3, N, 3, S, S, 1 + 4 + class_offset) . . S = scale_size\r\n",
    "               + loss_func(pred[1], batch_label[1], scales[1], anchors=anchors[1])    # batch_label: tensor(3, N, 3, S, S, 1 + 4 + class_offset)\r\n",
    "               + loss_func(pred[2], batch_label[2], scales[2], anchors=anchors[2]) )  ##### anchors: tensor(3,    3,       2) . . . is list of pairs(anch_w, anch_h)\r\n",
    "        loss /= 3\r\n",
    "\r\n",
    "        logger.add_scalar('train/loss', loss.item(), n_iteration)\r\n",
    "\r\n",
    "        # print(f\"loss: {loss}\")\r\n",
    "\r\n",
    "        #################\r\n",
    "        ## BACKWARDING ##\r\n",
    "        #################\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        torch.cuda.empty_cache()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def valid(\r\n",
    "        model,\r\n",
    "        valid_loader,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device)       ## [19, 38, 76]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device)\r\n",
    "    coco_evaluator = CocoEval()\r\n",
    "\r\n",
    "    for i, batch_input in enumerate(tqdm(valid_loader, desc=\"valid\")):\r\n",
    "        batch_img = batch_input[\"img\"].to(device)\r\n",
    "        batch_input[\"label_map\"] = compress_label_map(batch_input[\"label_map\"], anchors, scales)\r\n",
    "        \r\n",
    "        pred = model(batch_img)\r\n",
    "        coco_evaluator.update(batch_input, pred)\r\n",
    "\r\n",
    "    ## Examine Accuracy\r\n",
    "    mean_average_precision = coco_evaluator.eval()\r\n",
    "    logger.add_scalar('test/map', mean_average_precision, epoch)\r\n",
    "\r\n",
    "    return mean_average_precision\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import easydict\r\n",
    "\r\n",
    "args = easydict.EasyDict({\r\n",
    "    \"config\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolov3.cfg\",\r\n",
    "    # \"weight\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.weights\",\r\n",
    "    \"dataset\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/dataset/yolo_dataset.yml\",\r\n",
    "    \"model\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolo_model.yml\",\r\n",
    "    \"optimizer\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/optimizer/optimizer.yml\",\r\n",
    "    \"weight_save_dir\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/weights\"\r\n",
    "})\r\n",
    "\r\n",
    "\r\n",
    "dataset_option = yaml_parser(args.dataset)\r\n",
    "model_option = yaml_parser(args.model)\r\n",
    "optimizer_option = yaml_parser(args.optimizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "######################\r\n",
    "## BUILD DATALOADER ##\r\n",
    "######################\r\n",
    "# train_set_num, train_loader, _ = build_DataLoader(dataset_option, model_option, optimizer_option)\r\n",
    "\r\n",
    "train_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "train_loader = DataLoader(train_dataset, batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"], shuffle=True, collate_fn=collate_fn)\r\n",
    "valid_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"], shuffle=True, collate_fn=collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# device = torch.device('cpu')\r\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "###########################\r\n",
    "## BUILD MODEL & LOSS_fn ##\r\n",
    "###########################\r\n",
    "# model = DarknetParser(args.config, args.weight)\r\n",
    "model = Darknet4YOLOv3(args.config).to(device)\r\n",
    "model = torch.nn.DataParallel(model)\r\n",
    "loss_function = YOLOv3Loss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=optimizer_option[\"OPTIMIZER\"][\"LR\"])\r\n",
    "optimizer_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] = len(train_dataset) // optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "logger = SummaryWriter()\r\n",
    "\r\n",
    "if not os.path.isdir(args.weight_save_dir):\r\n",
    "    os.makedirs(args.weight_save_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "epochs = optimizer_option[\"OPTIMIZER\"][\"EPOCHS\"]\r\n",
    "for epoch in range(epochs):\r\n",
    "    ###########\r\n",
    "    ## TRAIN ##\r\n",
    "    ###########\r\n",
    "    train(\r\n",
    "            model,\r\n",
    "            train_loader,\r\n",
    "            loss_function,\r\n",
    "            optimizer,\r\n",
    "            optimizer_option,\r\n",
    "            model_option,\r\n",
    "            device,\r\n",
    "            epoch,\r\n",
    "            logger,\r\n",
    "            )\r\n",
    "    \r\n",
    "    ###########\r\n",
    "    ## VALID ##\r\n",
    "    ###########\r\n",
    "    acc = valid(\r\n",
    "                    model,\r\n",
    "                    valid_loader,\r\n",
    "                    model_option,\r\n",
    "                    device,\r\n",
    "                    epoch,\r\n",
    "                    logger\r\n",
    "                    )\r\n",
    "    \r\n",
    "    print(f\"Epoch: ({epoch + 1}/{epochs}) . . . [acc: {acc:.2f}]\")\r\n",
    "    save_checkpoint(epoch,\r\n",
    "                    acc,\r\n",
    "                    model,\r\n",
    "                    optimizer,\r\n",
    "                    # scheduler,\r\n",
    "                    # scaler,\r\n",
    "                    path=args.weight_save_dir\r\n",
    "                    )\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "train: 100%|██████████| 1000/1000 [06:47<00:00,  2.45it/s]\n",
      "valid:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\ryyoon\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:579: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(other, self)\n",
      "valid: 100%|██████████| 1000/1000 [03:28<00:00,  4.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.682\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.682\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.908\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.898\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.908\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.227\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.682\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.914\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.908\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.910\n",
      "Epoch: (1/1) . . . [acc: 0.68]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "3cbf2cfe2af17255c7550a0a36495165331228ad52d7cf7dc2787e8b35bbde01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}