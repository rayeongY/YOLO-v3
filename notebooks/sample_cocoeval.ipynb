{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"sample_cocoeval.ipynb\"))))\r\n",
    "\r\n",
    "from data.yolo_dataset import YoloDataset\r\n",
    "\r\n",
    "import torch\r\n",
    "import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "dataset = YoloDataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def train(\r\n",
    "        model,\r\n",
    "        train_loader,\r\n",
    "        loss_func,\r\n",
    "        optimizer,\r\n",
    "        optim_option,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device)       ## [13, 26, 52]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device)\r\n",
    "\r\n",
    "    for i, batch_input in enumerate(tqdm(train_loader, desc=\"train\")):\r\n",
    "        n_iteration = (optim_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] * epoch) + i\r\n",
    "\r\n",
    "        batch_img = batch_input[\"img\"].to(device)\r\n",
    "        batch_label = [label.to(device) for label in batch_input[\"label_map\"]]\r\n",
    "        \r\n",
    "        #################\r\n",
    "        ##  FORWARDING ##\r\n",
    "        #################\r\n",
    "        pred = model(batch_img)                                                       ### batch_img: tensor(   N, 3, 608, 608) . . . . . . . . . . . N = batch_size\r\n",
    "        loss = ( loss_func(pred[0], batch_label[0], scales[0], anchors=anchors[0])    ######## pred: tensor(3, N, 3, S, S, 1 + 4 + class_offset) . . S = scale_size\r\n",
    "               + loss_func(pred[1], batch_label[1], scales[1], anchors=anchors[1])    # batch_label: tensor(3, N, 3, S, S, 1 + 4 + class_offset)\r\n",
    "               + loss_func(pred[2], batch_label[2], scales[2], anchors=anchors[2]) )  ##### anchors: tensor(3,    3,       2) . . . is list of pairs(anch_w, anch_h)\r\n",
    "        loss /= 3\r\n",
    "\r\n",
    "        logger.add_scalar('train/loss', loss.item(), n_iteration)\r\n",
    "\r\n",
    "        # print(f\"loss: {loss}\")\r\n",
    "\r\n",
    "        #################\r\n",
    "        ## BACKWARDING ##\r\n",
    "        #################\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        torch.cuda.empty_cache()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from pycocotools.coco import COCO\r\n",
    "from pycocotools.cocoeval import COCOeval\r\n",
    "\r\n",
    "## https://www.programcreek.com/python/example/88588/pycocotools.cocoeval.COCOeval"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchvision\r\n",
    "\r\n",
    "class COCOevaluator(object):\r\n",
    "    def __init__(self, dataloader, iou_type=\"bbox\"):\r\n",
    "        super(COCOevaluator, self).__init__()\r\n",
    "\r\n",
    "        self.cocogt = self.create_cocogt(dataloader.dataset)\r\n",
    "        self.cocodt = []\r\n",
    "        self.evaluator = COCOeval(cocoGt=self.cocogt, iouType=iou_type)\r\n",
    "\r\n",
    "\r\n",
    "    def update_preds(self, pred):\r\n",
    "\r\n",
    "        self.cocodt.append(pred)\r\n",
    "\r\n",
    "\r\n",
    "    def create_cocogt(self, dataset):\r\n",
    "        for _ in range(10):\r\n",
    "            if isinstance(dataset, torchvision.datasets.CocoDetection):\r\n",
    "                break\r\n",
    "            if isinstance(dataset, torch.utils.data.Subset):\r\n",
    "                dataset = dataset.dataset\r\n",
    "\r\n",
    "        if isinstance(dataset, torchvision.datasets.CocoDetection):\r\n",
    "            return dataset.coco\r\n",
    "\r\n",
    "        cocogt = COCO()\r\n",
    "\r\n",
    "        ann_id = 1      ## There was an issue: WHY `ann_id` should be initialized to 1 ----- https://github.com/pytorch/vision/issues/1530\r\n",
    "                        ## In short, the list of class IDs is used as BOOLEAN values\r\n",
    "                        ##        => So if `ann_id` is initialized to 0, then the `0th ID` is interpreted as a NEGATIVE\r\n",
    "\r\n",
    "        dataset = {'images': [], 'categories': [], 'annotations': []}\r\n",
    "        categories = set()\r\n",
    "        for img_idx in range(len(dataset)):\r\n",
    "            # find better way to get target\r\n",
    "            # targets = dataset.get_annotations(img_idx)\r\n",
    "            img, labels, img_path, _ = dataset[img_idx]           ## __getitem__ RETURN: (img, labels, img_path, label_maps)\r\n",
    "\r\n",
    "            img_dict = {}\r\n",
    "\r\n",
    "            image_id = os.path.splitext(img_path)[0]    ## e.g. \"daecheon_20201113_0000_011\"\r\n",
    "            img_dict['id'] = image_id\r\n",
    "            img_dict['height'] = img.shape[-2]\r\n",
    "            img_dict['width'] = img.shape[-1]\r\n",
    "\r\n",
    "            dataset['images'].append(img_dict)\r\n",
    "\r\n",
    "            labels = labels[..., 0].tolist()\r\n",
    "            bboxes = labels[..., 1:5]\r\n",
    "            bboxes[..., :2] -= (bboxes[..., 2:] / 2)\r\n",
    "            bboxes = bboxes.tolist()\r\n",
    "\r\n",
    "            areas = (bboxes[..., 2:3] * bboxes[..., 3:4]).tolist()    #######################\r\n",
    "            iscrowd = targets['iscrowd'].tolist()                     #######################\r\n",
    "\r\n",
    "            num_objs = len(bboxes)\r\n",
    "            for i in range(num_objs):\r\n",
    "                ann = {}\r\n",
    "                ann['image_id'] = image_id\r\n",
    "                ann['bbox'] = bboxes[i]\r\n",
    "                ann['category_id'] = labels[i]\r\n",
    "\r\n",
    "                categories.add(labels[i])\r\n",
    "\r\n",
    "                ann['area'] = areas[i]\r\n",
    "                ann['iscrowd'] = iscrowd[i]\r\n",
    "                ann['id'] = ann_id\r\n",
    "\r\n",
    "                dataset['annotations'].append(ann)\r\n",
    "                ann_id += 1\r\n",
    "\r\n",
    "        dataset['categories'] = [{'id': i} for i in sorted(categories)]\r\n",
    "        cocogt.dataset = dataset\r\n",
    "        cocogt.createIndex()\r\n",
    "        \r\n",
    "        return cocogt\r\n",
    "\r\n",
    "\r\n",
    "    def evaluation(self):\r\n",
    "        self.evaluator.evaluate()\r\n",
    "        self.evaluator.accumulate()\r\n",
    "        self.evaluator.summarize()\r\n",
    "\r\n",
    "        mean_average_precision = self.evaluator.stats[0].item()\r\n",
    "\r\n",
    "        return mean_average_precision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def valid(\r\n",
    "        model,\r\n",
    "        valid_loader,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    coco_evaluator = COCOevaluator(valid_loader.dataset)\r\n",
    "\r\n",
    "    for i, batch_input in enumerate(tqdm(valid_loader, desc=\"valid\")):\r\n",
    "        batch_img = batch_input[\"img\"].to(device)\r\n",
    "        batch_label = [label.to(device) for label in batch_input[\"label_map\"]]\r\n",
    "        batch_size = len(batch_input[\"img_path\"])\r\n",
    "        \r\n",
    "        pred = model(batch_img)\r\n",
    "        # surpressed_pred = NMS(pred, batch_size)\r\n",
    "        coco_evaluator.update_preds(pred)\r\n",
    "\r\n",
    "\r\n",
    "    ## Examine Accuracy: mean Average Precision\r\n",
    "    mean_average_precision = coco_evaluator.evaluation()\r\n",
    "    logger.add_scalar('test/map', mean_average_precision, epoch)\r\n",
    "\r\n",
    "    return mean_average_precision\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "3cbf2cfe2af17255c7550a0a36495165331228ad52d7cf7dc2787e8b35bbde01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}