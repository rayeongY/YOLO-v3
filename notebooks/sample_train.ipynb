{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "import argparse\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"sample_train.ipynb\"))))\r\n",
    "from common.parser import yaml_parser\r\n",
    "from common.recoder import save_checkpoint\r\n",
    "from data.yolo_dataset import *\r\n",
    "from model.MyYOLOv3 import YOLOv3Loss\r\n",
    "from model.darknet2pytorch import DarknetParser\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "def train(\r\n",
    "        model,\r\n",
    "        train_loader,\r\n",
    "        loss_func,\r\n",
    "        optimizer,\r\n",
    "        dataset_option,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device)       ## [13, 26, 52]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device)\r\n",
    "\r\n",
    "    for i, (batch_img, batch_label, batch_img_path) in enumerate(train_loader, 0):\r\n",
    "        n_iteration = (optimizer_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] * epoch) + i\r\n",
    "\r\n",
    "        batch_img = batch_img.to(device)\r\n",
    "        batch_label = (batch_label[0].to(device), batch_label[1].to(device), batch_label[2].to(device))\r\n",
    "        \r\n",
    "        #################\r\n",
    "        ##  FORWARDING ##\r\n",
    "        #################\r\n",
    "        pred = model(batch_img)                                                       ### batch_img: tensor(   N, 3, 608, 608) . . . . . . . . . . . N = batch_size\r\n",
    "        pred = pred.data.cpu().numpy()\r\n",
    "        loss = ( loss_func(pred[2], batch_label[0], scales[0], anchors=anchors[0])    ######## pred: tensor(3, N, 3, S, S, 1 + 4 + class_offset) . . S = scale_size\r\n",
    "               + loss_func(pred[1], batch_label[1], scales[1], anchors=anchors[1])    # batch_label: tensor(3, N, 3, S, S, 1 + 4 + class_offset)\r\n",
    "               + loss_func(pred[0], batch_label[2], scales[2], anchors=anchors[2]) )  ##### anchors: tensor(3,    3,       2) . . . is list of pairs(anch_w, anch_h)\r\n",
    "        loss /= 3\r\n",
    "\r\n",
    "        logger.add_scalar('train/loss', loss.item(), n_iteration)\r\n",
    "\r\n",
    "        # print(f\"loss: {loss}\")\r\n",
    "\r\n",
    "        #################\r\n",
    "        ## BACKWARDING ##\r\n",
    "        #################\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        torch.cuda.empty_cache()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "def valid(\r\n",
    "        model,\r\n",
    "        valid_loader,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.eval()\r\n",
    "    true_pred_num = 0\r\n",
    "    gt_num = 0\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device)       ## [13, 26, 52]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device)\r\n",
    "\r\n",
    "    for i, (batch_img, batch_label, batch_img_path) in enumerate(valid_loader, 0):\r\n",
    "        batch_img = batch_img.to(device)\r\n",
    "        batch_label = batch_label.to(device)\r\n",
    "        \r\n",
    "        pred = model(batch_img)\r\n",
    "\r\n",
    "        ## Post-Processing?\r\n",
    "\r\n",
    "        ## Get the number of both true predictions and ground truth\r\n",
    "\r\n",
    "\r\n",
    "    ## Examine Accuracy\r\n",
    "    acc = (true_pred_num / gt_num + 1e-16) * 100\r\n",
    "    logger.add_scalar('test/acc', acc, epoch)\r\n",
    "\r\n",
    "    return acc\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# parser = argparse.ArgumentParser()\r\n",
    "\r\n",
    "# parser.add_argument(\"--config\", type=str, default=\"C:/Users/ryyoon/RY_GitHub/Lets_Pytorch/YOLO-v3/configs/darknet/yolov4.cfg\")\r\n",
    "# parser.add_argument(\"--weight\", type=str, default=\"C:/Users/ryyoon/RY_GitHub/Lets_Pytorch/YOLO-v3/configs/darknet/yolov4.weights\")\r\n",
    "\r\n",
    "# parser.add_argument(\"--dataset\", type=str, default=\"C:/Users/ryyoon/RY_GitHub/Lets_Pytorch/YOLO-v3/configs/dataset/yolo_dataset.yml\")\r\n",
    "# parser.add_argument(\"--model\", type=str, default=\"C:/Users/ryyoon/RY_GitHub/Lets_Pytorch/YOLO-v3/configs/model/yolo_model.yml\")\r\n",
    "# parser.add_argument(\"--optimizer\", type=str, default=\"C:/Users/ryyoon/RY_GitHub/Lets_Pytorch/YOLO-v3/configs/optimizer/optimizer.yml\")\r\n",
    "\r\n",
    "# parser.add_argument(\"--weight-save-dir\", type=str, default=\"C:/Users/ryyoon/RY_GitHub/Lets_Pytorch/YOLO-v3/weights\")\r\n",
    "\r\n",
    "# args = parser.parse_args()\r\n",
    "\r\n",
    "import easydict\r\n",
    "\r\n",
    "args = easydict.EasyDict({\r\n",
    "    \"config\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.cfg\",\r\n",
    "    \"weight\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.weights\",\r\n",
    "    \"dataset\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/dataset/yolo_dataset.yml\",\r\n",
    "    \"model\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolo_model.yml\",\r\n",
    "    \"optimizer\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/optimizer/optimizer.yml\",\r\n",
    "    \"weight_save_dir\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/weights\"\r\n",
    "})\r\n",
    "\r\n",
    "\r\n",
    "dataset_option = yaml_parser(args.dataset)\r\n",
    "model_option = yaml_parser(args.model)\r\n",
    "optimizer_option = yaml_parser(args.optimizer)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "######################\r\n",
    "## BUILD DATALOADER ##\r\n",
    "######################\r\n",
    "# train_set_num, train_loader, _ = build_DataLoader(dataset_option, model_option, optimizer_option)\r\n",
    "\r\n",
    "train_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "train_loader = DataLoader(train_dataset, batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"], shuffle=True, collate_fn=collate_fn)\r\n",
    "valid_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"], shuffle=True, collate_fn=collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "device = torch.device('cpu')\r\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "###########################\r\n",
    "## BUILD MODEL & LOSS_fn ##\r\n",
    "###########################\r\n",
    "# model = DarknetParser(args.config, args.weight)\r\n",
    "model = DarknetParser(args.config, args.weight).to(device)\r\n",
    "model = torch.nn.DataParallel(model)\r\n",
    "loss_function = YOLOv3Loss()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "parse from 'C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.cfg'\n",
      "done\n",
      "\n",
      "load weights from : 'C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.weights'\n",
      "Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0 convolutional load weights : [0.004]/[245.779] mb\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "1 convolutional load weights : [0.075]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2 convolutional load weights : [0.092]/[245.779] mb\n",
      "3 route        load weights : [0.092]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "4 convolutional load weights : [0.108]/[245.779] mb\n",
      "Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "5 convolutional load weights : [0.117]/[245.779] mb\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "6 convolutional load weights : [0.188]/[245.779] mb\n",
      "7 shortcut     load weights : [0.188]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "8 convolutional load weights : [0.204]/[245.779] mb\n",
      "9 route        load weights : [0.204]/[245.779] mb\n",
      "Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "10 convolutional load weights : [0.237]/[245.779] mb\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "11 convolutional load weights : [0.520]/[245.779] mb\n",
      "Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "12 convolutional load weights : [0.552]/[245.779] mb\n",
      "13 route        load weights : [0.552]/[245.779] mb\n",
      "Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "14 convolutional load weights : [0.584]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "15 convolutional load weights : [0.601]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "16 convolutional load weights : [0.743]/[245.779] mb\n",
      "17 shortcut     load weights : [0.743]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "18 convolutional load weights : [0.759]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "19 convolutional load weights : [0.901]/[245.779] mb\n",
      "20 shortcut     load weights : [0.901]/[245.779] mb\n",
      "Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "21 convolutional load weights : [0.917]/[245.779] mb\n",
      "22 route        load weights : [0.917]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "23 convolutional load weights : [0.982]/[245.779] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "24 convolutional load weights : [2.111]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "25 convolutional load weights : [2.238]/[245.779] mb\n",
      "26 route        load weights : [2.238]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "27 convolutional load weights : [2.365]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "28 convolutional load weights : [2.429]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "29 convolutional load weights : [2.994]/[245.779] mb\n",
      "30 shortcut     load weights : [2.994]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "31 convolutional load weights : [3.058]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "32 convolutional load weights : [3.622]/[245.779] mb\n",
      "33 shortcut     load weights : [3.622]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "34 convolutional load weights : [3.687]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "35 convolutional load weights : [4.251]/[245.779] mb\n",
      "36 shortcut     load weights : [4.251]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "37 convolutional load weights : [4.316]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "38 convolutional load weights : [4.880]/[245.779] mb\n",
      "39 shortcut     load weights : [4.880]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "40 convolutional load weights : [4.945]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "41 convolutional load weights : [5.509]/[245.779] mb\n",
      "42 shortcut     load weights : [5.509]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "43 convolutional load weights : [5.574]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "44 convolutional load weights : [6.138]/[245.779] mb\n",
      "45 shortcut     load weights : [6.138]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "46 convolutional load weights : [6.203]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "47 convolutional load weights : [6.767]/[245.779] mb\n",
      "48 shortcut     load weights : [6.767]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "49 convolutional load weights : [6.831]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "50 convolutional load weights : [7.396]/[245.779] mb\n",
      "51 shortcut     load weights : [7.396]/[245.779] mb\n",
      "Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "52 convolutional load weights : [7.460]/[245.779] mb\n",
      "53 route        load weights : [7.460]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "54 convolutional load weights : [7.714]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "55 convolutional load weights : [12.222]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "56 convolutional load weights : [12.726]/[245.779] mb\n",
      "57 route        load weights : [12.726]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "58 convolutional load weights : [13.230]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "59 convolutional load weights : [13.484]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "60 convolutional load weights : [15.738]/[245.779] mb\n",
      "61 shortcut     load weights : [15.738]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "62 convolutional load weights : [15.992]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "63 convolutional load weights : [18.245]/[245.779] mb\n",
      "64 shortcut     load weights : [18.245]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "65 convolutional load weights : [18.499]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "66 convolutional load weights : [20.753]/[245.779] mb\n",
      "67 shortcut     load weights : [20.753]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "68 convolutional load weights : [21.007]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "69 convolutional load weights : [23.261]/[245.779] mb\n",
      "70 shortcut     load weights : [23.261]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "71 convolutional load weights : [23.515]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "72 convolutional load weights : [25.769]/[245.779] mb\n",
      "73 shortcut     load weights : [25.769]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "74 convolutional load weights : [26.023]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "75 convolutional load weights : [28.277]/[245.779] mb\n",
      "76 shortcut     load weights : [28.277]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "77 convolutional load weights : [28.531]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "78 convolutional load weights : [30.785]/[245.779] mb\n",
      "79 shortcut     load weights : [30.785]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "80 convolutional load weights : [31.038]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "81 convolutional load weights : [33.292]/[245.779] mb\n",
      "82 shortcut     load weights : [33.292]/[245.779] mb\n",
      "Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "83 convolutional load weights : [33.546]/[245.779] mb\n",
      "84 route        load weights : [33.546]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "85 convolutional load weights : [34.554]/[245.779] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "86 convolutional load weights : [52.570]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "87 convolutional load weights : [54.578]/[245.779] mb\n",
      "88 route        load weights : [54.578]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "89 convolutional load weights : [56.585]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "90 convolutional load weights : [57.593]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "91 convolutional load weights : [66.601]/[245.779] mb\n",
      "92 shortcut     load weights : [66.601]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "93 convolutional load weights : [67.609]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "94 convolutional load weights : [76.617]/[245.779] mb\n",
      "95 shortcut     load weights : [76.617]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "96 convolutional load weights : [77.624]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "97 convolutional load weights : [86.632]/[245.779] mb\n",
      "98 shortcut     load weights : [86.632]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "99 convolutional load weights : [87.640]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "100 convolutional load weights : [96.648]/[245.779] mb\n",
      "101 shortcut     load weights : [96.648]/[245.779] mb\n",
      "Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "102 convolutional load weights : [97.656]/[245.779] mb\n",
      "103 route        load weights : [97.656]/[245.779] mb\n",
      "Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "104 convolutional load weights : [101.671]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "105 convolutional load weights : [103.679]/[245.779] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "106 convolutional load weights : [121.695]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "107 convolutional load weights : [123.703]/[245.779] mb\n",
      "108 maxpool      load weights : [123.703]/[245.779] mb\n",
      "109 route        load weights : [123.703]/[245.779] mb\n",
      "110 maxpool      load weights : [123.703]/[245.779] mb\n",
      "111 route        load weights : [123.703]/[245.779] mb\n",
      "112 maxpool      load weights : [123.703]/[245.779] mb\n",
      "113 route        load weights : [123.703]/[245.779] mb\n",
      "Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "114 convolutional load weights : [127.710]/[245.779] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "115 convolutional load weights : [145.726]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "116 convolutional load weights : [147.734]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "117 convolutional load weights : [148.238]/[245.779] mb\n",
      "118 upsample     load weights : [148.238]/[245.779] mb\n",
      "119 route        load weights : [148.238]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "120 convolutional load weights : [148.742]/[245.779] mb\n",
      "121 route        load weights : [148.742]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "122 convolutional load weights : [149.245]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "123 convolutional load weights : [153.753]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "124 convolutional load weights : [154.257]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "125 convolutional load weights : [158.765]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "126 convolutional load weights : [159.269]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "127 convolutional load weights : [159.396]/[245.779] mb\n",
      "128 upsample     load weights : [159.396]/[245.779] mb\n",
      "129 route        load weights : [159.396]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "130 convolutional load weights : [159.523]/[245.779] mb\n",
      "131 route        load weights : [159.523]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "132 convolutional load weights : [159.650]/[245.779] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "133 convolutional load weights : [160.779]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "134 convolutional load weights : [160.906]/[245.779] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "135 convolutional load weights : [162.035]/[245.779] mb\n",
      "Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "136 convolutional load weights : [162.161]/[245.779] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "137 convolutional load weights : [163.290]/[245.779] mb\n",
      "Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "138 convolutional load weights : [163.540]/[245.779] mb\n",
      "139 yolo         load weights : [163.540]/[245.779] mb\n",
      "140 route        load weights : [163.540]/[245.779] mb\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "141 convolutional load weights : [164.669]/[245.779] mb\n",
      "142 route        load weights : [164.669]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "143 convolutional load weights : [165.173]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "144 convolutional load weights : [169.681]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "145 convolutional load weights : [170.185]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "146 convolutional load weights : [174.693]/[245.779] mb\n",
      "Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "147 convolutional load weights : [175.197]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "148 convolutional load weights : [179.704]/[245.779] mb\n",
      "Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "149 convolutional load weights : [180.203]/[245.779] mb\n",
      "150 yolo         load weights : [180.203]/[245.779] mb\n",
      "151 route        load weights : [180.203]/[245.779] mb\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "152 convolutional load weights : [184.711]/[245.779] mb\n",
      "153 route        load weights : [184.711]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "154 convolutional load weights : [186.719]/[245.779] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "155 convolutional load weights : [204.735]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "156 convolutional load weights : [206.743]/[245.779] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "157 convolutional load weights : [224.758]/[245.779] mb\n",
      "Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "158 convolutional load weights : [226.766]/[245.779] mb\n",
      "Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "159 convolutional load weights : [244.782]/[245.779] mb\n",
      "Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "160 convolutional load weights : [245.779]/[245.779] mb\n",
      "161 yolo         load weights : [245.779]/[245.779] mb\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=optimizer_option[\"OPTIMIZER\"][\"LR\"])\r\n",
    "optimizer_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] = len(train_dataset) // optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\r\n",
    "logger = SummaryWriter()\r\n",
    "\r\n",
    "if not os.path.isdir(args.weight_save_dir):\r\n",
    "    os.makedirs(args.weight_save_dir)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\r\n",
    "epochs = optimizer_option[\"OPTIMIZER\"][\"EPOCHS\"]\r\n",
    "for epoch in range(epochs):\r\n",
    "    ###########\r\n",
    "    ## TRAIN ##\r\n",
    "    ###########\r\n",
    "    train(\r\n",
    "            model,\r\n",
    "            train_loader,\r\n",
    "            loss_function,\r\n",
    "            optimizer,\r\n",
    "            dataset_option,\r\n",
    "            model_option,\r\n",
    "            device,\r\n",
    "            epoch,\r\n",
    "            logger,\r\n",
    "            )\r\n",
    "\r\n",
    "    ###########\r\n",
    "    ## VALID ##\r\n",
    "    ###########\r\n",
    "    acc = valid(\r\n",
    "                model,\r\n",
    "                train_loader,\r\n",
    "                model_option,\r\n",
    "                device,\r\n",
    "                epoch,\r\n",
    "                logger\r\n",
    "                )\r\n",
    "\r\n",
    "    print(f\"Epoch: ({epoch + 1}/{epochs}) . . . [acc: {acc:.2f}]\")\r\n",
    "    save_checkpoint(epoch,\r\n",
    "                    acc,\r\n",
    "                    model,\r\n",
    "                    optimizer,\r\n",
    "                    # scheduler,\r\n",
    "                    # scaler,\r\n",
    "                    path=args.weight_save_dir\r\n",
    "                    )"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Index put requires the source and destination dtypes match, got Double for the destination and Float for the source.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a4d31056c1b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m## TRAIN ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m###########\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     train(\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-47a8e01269c0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, loss_func, optimizer, dataset_option, model_option, device, epoch, logger)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0manchors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_option\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"YOLOv3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ANCHORS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_img_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mn_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moptimizer_option\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OPTIMIZER\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ITERS_PER_EPOCH\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ryyoon\\RY_GitHub\\YOLO-v3\\data\\yolo_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_cell_occupied\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scale_occupied\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m       \u001b[1;31m## if there is no other overlapping-liked bbox and I'm the best\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                     \u001b[0mlabel_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manch_idx_in_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                     \u001b[0mlabel_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manch_idx_in_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgtBBOX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m                     \u001b[0mlabel_maps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manch_idx_in_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                     \u001b[0mis_scale_occupied\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m                             \u001b[1;31m## the best-fitted anchor has been picked in this scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Index put requires the source and destination dtypes match, got Double for the destination and Float for the source."
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "3cbf2cfe2af17255c7550a0a36495165331228ad52d7cf7dc2787e8b35bbde01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}