{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "import argparse\r\n",
    "\r\n",
    "import sys\r\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"sample_train.ipynb\"))))\r\n",
    "\r\n",
    "from common.parser import yaml_parser\r\n",
    "from common.recoder import save_checkpoint\r\n",
    "from common.cocoeval4yolo import CocoEval\r\n",
    "\r\n",
    "from data.yolo_dataset import *\r\n",
    "# from model.loss import YOLOv3Loss\r\n",
    "from model.model import Darknet4YOLOv3\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from common.utils import coord_IOU\r\n",
    "\r\n",
    "\r\n",
    "class YOLOv3Loss(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.mse = nn.MSELoss(reduction='none')\r\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\r\n",
    "        self.multiMargin = nn.MultiLabelSoftMarginLoss(reduction='none')        ## https://cvml.tistory.com/26\r\n",
    "                                                                \r\n",
    "\r\n",
    "        \r\n",
    "    def forward(self, pred, target, scale, anchors, logger, n_iter):\r\n",
    "        \r\n",
    "        ## no_obj_loss(No Object Loss):     Loss for objectness score      of non-object-assigned BBOXes\r\n",
    "        ## is_obj_loss(Object Loss):        Loss for objectness score      of     object-assigned BBOXes\r\n",
    "        ## coord_loss(Coordinates Loss):    Loss for predicted coordinates of     object-assigned BBOXes\r\n",
    "        ## class_loss(Classification Loss): Loss for predicted class-ids   of     object-assigned BBOXes \r\n",
    "        \r\n",
    "        is_assigned = target[..., 4] == 1     ## tensor([(element == 1) for element in 4th column of target])   ## e.g. tensor([True, False, False, ...])\r\n",
    "        no_assigned = target[..., 4] == 0     ## If use these boolean-list tensor as indices,\r\n",
    "                                              ##    we can extract the only rows from target(label) tensor -- whose 4th column element(objectness score) is 1-or-0\r\n",
    "\r\n",
    "    \r\n",
    "        no_obj_loss = self.get_loss(pred[..., 4:5][no_assigned], target[..., 4:5][no_assigned], opt=\"NO_OBJ\")\r\n",
    "        no_obj_loss = get_sum(no_obj_loss)\r\n",
    "        \r\n",
    "        logger.add_scalar('train/no_obj_loss', no_obj_loss.item(), n_iter)\r\n",
    "        if not (True in is_assigned):\r\n",
    "            # return no_obj_loss / 4\r\n",
    "            return no_obj_loss * 0.7\r\n",
    "\r\n",
    "        ## Before indexing, invert the prediction equations to the whole coordinates:(x, y, w, h) vectors\r\n",
    "        anchors = anchors.unsqueeze(0).unsqueeze(0).reshape((1, 3, 1, 1, 2))\r\n",
    "        scaled_pred = torch.cat([torch.sigmoid(pred[..., :2]), torch.exp(pred[..., 2:4]) * anchors, pred[..., 4:5]], dim=-1)\r\n",
    "        scaled_target = torch.cat([          target[..., :2],          target[..., 2:4]  * scale, target[..., 4:5]], dim=-1)\r\n",
    "        \r\n",
    "        is_obj_loss = self.get_loss(   scaled_pred[is_assigned],    scaled_target[is_assigned], opt=\"IS_OBJ\")\r\n",
    "        coord_loss =  self.get_loss(pred[..., 0:4][is_assigned], target[..., 0:4][is_assigned], opt=\"COORD\")\r\n",
    "        class_loss =  self.get_loss(pred[..., 5: ][is_assigned], target[..., 5: ][is_assigned], opt=\"CLASS\")\r\n",
    "\r\n",
    "        is_obj_loss = get_sum(is_obj_loss)\r\n",
    "        coord_loss = get_sum(coord_loss)\r\n",
    "        class_loss = get_sum(class_loss)\r\n",
    "    \r\n",
    "        # total_loss = (no_obj_loss\r\n",
    "        #             + is_obj_loss\r\n",
    "        #             + coord_loss\r\n",
    "        #             + class_loss) / 4\r\n",
    "        total_loss = (no_obj_loss * 0.7\r\n",
    "                    + is_obj_loss * 0.1\r\n",
    "                    + coord_loss * 0.1\r\n",
    "                    + class_loss * 0.1)\r\n",
    "\r\n",
    "        logger.add_scalar('train/is_obj_loss', is_obj_loss.item(), n_iter)\r\n",
    "        logger.add_scalar('train/coord_loss', coord_loss.item(), n_iter)\r\n",
    "        logger.add_scalar('train/class_loss', class_loss.item(), n_iter)\r\n",
    "\r\n",
    "        return total_loss\r\n",
    "\r\n",
    "\r\n",
    "    def get_loss(self, pred, target, opt):\r\n",
    "        \r\n",
    "        if opt == \"NO_OBJ\":\r\n",
    "            # loss = self.bce(torch.sigmoid(pred), target)\r\n",
    "            loss = self.bce(pred, target)\r\n",
    "            return loss\r\n",
    "\r\n",
    "        elif opt == \"IS_OBJ\":\r\n",
    "            ## Get iou values between predBBOX and gtBBOX\r\n",
    "            ## Because...\r\n",
    "            ## (1) These loss-calculations are done at grid-cell scale\r\n",
    "            ## (2) and 'objectness score(confidence score)' indicates how much \r\n",
    "            iou = coord_IOU(pred[..., 0:4], target[..., 0:4])\r\n",
    "            # loss = self.mse(torch.sigmoid(pred[..., 4:5]), target[..., 4:5])\r\n",
    "            loss = self.mse(pred[..., 4:5], target[..., 4:5])\r\n",
    "            # loss = self.mse(pred[..., 4:5], iou * target[..., 4:5])    ## If use [iou * target] instead of [target], MSE loss is better . . . maybe.\r\n",
    "            return loss                                          ##    cause [target] and [iou * target] values differ in \"Discrete\"/\"Continuous\"\r\n",
    "\r\n",
    "        elif opt == \"COORD\":\r\n",
    "            loss = self.mse(pred, target) / 4\r\n",
    "            return loss\r\n",
    "\r\n",
    "        elif opt == \"CLASS\":\r\n",
    "            num_classes = target.shape[-1]\r\n",
    "            loss = self.multiMargin(pred.reshape(-1, num_classes), target.reshape(-1, num_classes))\r\n",
    "            return loss\r\n",
    "\r\n",
    "\r\n",
    "def get_sum(loss):\r\n",
    "    return loss.sum() / loss.shape[0] if loss.shape[0] != 0 else loss.sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def train(\r\n",
    "        model,\r\n",
    "        train_loader,\r\n",
    "        loss_func,\r\n",
    "        optimizer,\r\n",
    "        optim_option,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        lr_scheduler,\r\n",
    "        # scaler,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.train()\r\n",
    "\r\n",
    "    scales = torch.tensor(model_option[\"YOLOv3\"][\"SCALES\"]).to(device)       ## [19, 38, 76]\r\n",
    "    anchors = torch.tensor(model_option[\"YOLOv3\"][\"ANCHORS\"]).to(device)\r\n",
    "\r\n",
    "    for i, batch_input in enumerate(tqdm(train_loader, desc=\"train\")):\r\n",
    "        n_iteration = (optim_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] * epoch) + i\r\n",
    "\r\n",
    "        batch_img = batch_input[\"img\"].to(device)\r\n",
    "        batch_label = [label.to(device) for label in batch_input[\"label_map\"]]\r\n",
    "        \r\n",
    "        #################\r\n",
    "        ##  FORWARDING ##\r\n",
    "        #################\r\n",
    "        with torch.autograd.set_detect_anomaly(True):\r\n",
    "            with torch.cuda.amp.autocast():\r\n",
    "                pred = model(batch_img)                                                       ### batch_img: tensor(   N, 3, 608, 608) . . . . . . . . . . . N = batch_size\r\n",
    "                loss = ( loss_func(pred[0], batch_label[0], scales[0], anchors[0], logger, n_iteration)    ######## pred: tensor(3, N, 3, S, S, 1 + 4 + class_offset) . . S = scale_size\r\n",
    "                       + loss_func(pred[1], batch_label[1], scales[1], anchors[1], logger, n_iteration)    # batch_label: tensor(3, N, 3, S, S, 1 + 4 + class_offset)\r\n",
    "                       + loss_func(pred[2], batch_label[2], scales[2], anchors[2], logger, n_iteration) )  ##### anchors: tensor(3,    3,       2) . . . is list of pairs(anch_w, anch_h)\r\n",
    "\r\n",
    "\r\n",
    "            total_loss = loss / 3\r\n",
    "\r\n",
    "            logger.add_scalar('train/total_loss', total_loss.item(), n_iteration)\r\n",
    "\r\n",
    "            #################\r\n",
    "            ## BACKWARDING ##\r\n",
    "            #################\r\n",
    "            # scaler.scale(total_loss).backward()\r\n",
    "            # scaler.step(optimizer)\r\n",
    "            # optimizer.zero_grad()\r\n",
    "\r\n",
    "            # lr_scheduler.step()\r\n",
    "            # scaler.update()\r\n",
    "            try:\r\n",
    "                total_loss.backward()\r\n",
    "            except RuntimeError as e:\r\n",
    "                print(batch_input[\"img_path\"])\r\n",
    "            optimizer.step()\r\n",
    "        \r\n",
    "        if n_iteration > 800:       ## WHAT IS A WARM-UP ? ? ?\r\n",
    "            lr_scheduler.step()\r\n",
    "        else:\r\n",
    "            lr = optimizer_option[\"OPTIMIZER\"][\"LR\"] * float(n_iteration) / 100\r\n",
    "            for param_group in optimizer.param_groups:\r\n",
    "                param_group['lr'] = lr\r\n",
    "\r\n",
    "        # lr = optimizer_option[\"OPTIMIZER\"][\"LR\"] * float(n_iteration) / 100\r\n",
    "        # for param_group in optimizer.param_groups:\r\n",
    "        #     param_group['lr'] = lr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def valid(\r\n",
    "        model,\r\n",
    "        valid_loader,\r\n",
    "        model_option,\r\n",
    "        device,\r\n",
    "        epoch,\r\n",
    "        logger\r\n",
    "        ):\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    coco_evaluator = CocoEval()\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        # for i, batch_input in enumerate(valid_loader, 0):\r\n",
    "        for i, batch_input in enumerate(tqdm(valid_loader, desc=\"valid\")):\r\n",
    "            batch_img = batch_input[\"img\"].to(device)\r\n",
    "\r\n",
    "            pred = model(batch_img)\r\n",
    "            coco_evaluator.update(batch_input, pred)\r\n",
    "\r\n",
    "    ## Examine Accuracy\r\n",
    "    mean_average_precision = coco_evaluator.eval()\r\n",
    "    logger.add_scalar('test/map', mean_average_precision, epoch)\r\n",
    "\r\n",
    "    return mean_average_precision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import easydict\r\n",
    "\r\n",
    "args = easydict.EasyDict({\r\n",
    "    \"config\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolov3.cfg\",\r\n",
    "    # \"config\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov4.cfg\",\r\n",
    "    \"weight\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/darknet/yolov3-608.weights\",\r\n",
    "    \"dataset\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/dataset/yolo_dataset.yml\",\r\n",
    "    \"model\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/model/yolo_model.yml\",\r\n",
    "    \"optimizer\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/configs/optimizer/optimizer.yml\",\r\n",
    "    \"weight_save_dir\": \"C:/Users/ryyoon/RY_GitHub/YOLO-v3/weights\"\r\n",
    "})\r\n",
    "\r\n",
    "\r\n",
    "dataset_option = yaml_parser(args.dataset)\r\n",
    "model_option = yaml_parser(args.model)\r\n",
    "optimizer_option = yaml_parser(args.optimizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "######################\r\n",
    "## BUILD DATALOADER ##\r\n",
    "######################\r\n",
    "# train_set_num, train_loader, _ = build_DataLoader(dataset_option, model_option, optimizer_option)\r\n",
    "\r\n",
    "train_dataset = YoloDataset(dataset_option, model_option, split=\"train\")\r\n",
    "train_loader = DataLoader(train_dataset, batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"], shuffle=True, collate_fn=collate_fn)\r\n",
    "valid_dataset = YoloDataset(dataset_option, model_option, split=\"valid\")\r\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"], shuffle=True, collate_fn=collate_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# device = torch.device('cpu')\r\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "###########################\r\n",
    "## BUILD MODEL & LOSS_fn ##\r\n",
    "###########################\r\n",
    "# model = Darknet4YOLOv3(args.config, args.weight).to(device)\r\n",
    "model = Darknet4YOLOv3(args.config).to(device)\r\n",
    "model = torch.nn.DataParallel(model)\r\n",
    "loss_function = YOLOv3Loss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "param_groups = model.module.parameters() if isinstance(model, nn.DataParallel) else model.parameters()\r\n",
    "\r\n",
    "optimizer = torch.optim.Adam(\r\n",
    "    param_groups,\r\n",
    "    lr=optimizer_option[\"OPTIMIZER\"][\"LR\"],\r\n",
    ")\r\n",
    "for param_group in optimizer.param_groups:\r\n",
    "    param_group['lr'] = 0.\r\n",
    "optimizer_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] = len(train_dataset) // optimizer_option[\"OPTIMIZER\"][\"BATCH_SIZE\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# total_iter = optimizer_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] * optimizer_option[\"OPTIMIZER\"][\"EPOCHS\"]\r\n",
    "total_iter = optimizer_option[\"OPTIMIZER\"][\"ITERS_PER_EPOCH\"] * 10\r\n",
    "\r\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\r\n",
    "    optimizer,\r\n",
    "    lr_lambda=lambda epoch: 0.95 ** epoch\r\n",
    ")\r\n",
    "\r\n",
    "# Creates scaler once at the beginning of training\r\n",
    "scaler = torch.cuda.amp.GradScaler()\r\n",
    "\r\n",
    "logger = SummaryWriter()\r\n",
    "\r\n",
    "if not os.path.isdir(args.weight_save_dir):\r\n",
    "    os.makedirs(args.weight_save_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# epochs = optimizer_option[\"OPTIMIZER\"][\"EPOCHS\"]\r\n",
    "epochs = 3\r\n",
    "\r\n",
    "for epoch in range(epochs):\r\n",
    "    ###########\r\n",
    "    ## TRAIN ##\r\n",
    "    ###########\r\n",
    "    train(\r\n",
    "            model,\r\n",
    "            train_loader,\r\n",
    "            loss_function,\r\n",
    "            optimizer,\r\n",
    "            optimizer_option,\r\n",
    "            model_option,\r\n",
    "            device,\r\n",
    "            epoch,\r\n",
    "            lr_scheduler,\r\n",
    "            # scaler,\r\n",
    "            logger,\r\n",
    "    )\r\n",
    "    \r\n",
    "    ###########\r\n",
    "    ## VALID ##\r\n",
    "    ###########\r\n",
    "    mAP = valid(\r\n",
    "                    model,\r\n",
    "                    valid_loader,\r\n",
    "                    model_option,\r\n",
    "                    device,\r\n",
    "                    epoch,\r\n",
    "                    logger\r\n",
    "    )\r\n",
    "    \r\n",
    "    print(f\"Epoch: ({epoch + 1}/{epochs}) . . . [mAP: {mAP}]\")\r\n",
    "    save_checkpoint(epoch,\r\n",
    "                    mAP,\r\n",
    "                    model,\r\n",
    "                    optimizer,\r\n",
    "                    # lr_scheduler,\r\n",
    "                    # scaler,\r\n",
    "                    path=args.weight_save_dir\r\n",
    "                    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "train:  24%|██▎       | 2231/9468 [1:05:08<3:31:18,  1.75s/it]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Function 'ExpBackward' returned nan values in its 0th output.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a95954674de8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m## TRAIN ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m###########\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     train(\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d057b8ebc2cc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, loss_func, optimizer, optim_option, model_option, device, epoch, lr_scheduler, logger)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# scaler.update()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'ExpBackward' returned nan values in its 0th output."
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "3cbf2cfe2af17255c7550a0a36495165331228ad52d7cf7dc2787e8b35bbde01"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}